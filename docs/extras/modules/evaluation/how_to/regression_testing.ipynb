{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0fedc3eb-58d3-4001-9d52-699905aed710",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Regression Testing\n",
    "\n",
    "When dealing with model API's, it can be hard to know if the prediction quality has changed without proper regression testing. This guide will touch on three easy ways\n",
    "to regression test your model API's. We will use a QA system as an example. They all depend on constructing a dataset of inputs. It's best for inputs to be representative of your application domain.\n",
    "\n",
    "**Important:** As with any system, it's important to isolate what you want to test. If you are regression testing an LLM API, test it directly or mock other components of your application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c66c2025-8569-4955-a50a-bb66bd39413e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.evaluation.loading import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8095377-7751-4d1b-8303-051a48adc6c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b690d689-b338-4d74-8dbc-9debaaa6725d",
   "metadata": {},
   "source": [
    "\n",
    "## Approach 1: Compare Aggregate Performance\n",
    "\n",
    "The first approach is to construct an example dataset with reference examples. You can test the accuracy (or other metrics) of your model on a schedule to ensure the accuracy of your model is not degrading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee582f1-de66-4544-99ef-3bf672c13a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import  ChatOpenAI\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo-0631\", temperature=0)\n",
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7562c310-d80b-4461-96e0-d70bc94b3e9a",
   "metadata": {},
   "source": [
    "## Approach 2: Pairwise Compare Outputs\n",
    "\n",
    "The second way you can track changes and regressions is to compare outputs of the model on identical inputs. You can use a simple exact (or fuzzy) string match metric\n",
    "or use a model graded metric to ensure the meanings of the outputs are the same.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f47bdef5-7202-4523-b207-c0b6a7dd6da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
